{"p2":"Selecione quais agentes de usuário configurar, começando pelo asterisco (*) que se aplica a todos os rastreadores ou especificando mecanismos como Google e Bing. Defina quais pastas e tipos de arquivo os rastreadores podem ou não acessar. A ferramenta gera um arquivo robots.txt pronto para uso. Visualize os diretivos antes de download. Coloque o arquivo na raiz do seu domínio para controlar como os mecanismos indexam seu site.","p3":"Administradores de sites impedem que mecanismos de busca indexem conteúdo duplicado em ambientes de staging ou desenvolvimento. Equipes de SEO controlam quais páginas os rastreadores devem priorizar em sites com grande volume de conteúdo. Proprietários de e-commerce protegem páginas administrativas de serem indexadas publicamente. Gerentes de conteúdo usam robots.txt para canalizar recursos de rastreamento para conteúdo de maior valor.","p4":"Coloque seu arquivo robots.txt somente no diretório raiz do domínio—subdiretórios são ignorados pelos rastreadores. Use caminhos relativos começando com / para especificar pastas. Defina um User-agent apropriado para cada grupo de diretivas. Sempre inclua um Sitemap URL apontando para seu sitemap XML para ajudar mecanismos a descobrir todas as páginas.","p5":"While most major search engines respect robots.txt directives, it's not enforceable. Reputable crawlers follow the rules, but malicious bots often ignore them. Never use robots.txt for security—protect sensitive areas with proper authentication instead."}